{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpanTw_n_y1m"
      },
      "source": [
        "Based on the code from the original paper on DAAM (Tang et al., 2022).\n",
        "\n",
        "[Github repository](https://github.com/castorini/daam/tree/main?tab=readme-ov-file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv8OgMBt7yq4"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYS5uxdROIZV",
        "outputId": "29c5afce-4cfb-4835-9cc9-973df06aea27"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Go to the DAAM folder in Google Drive\n",
        "folder_path = '/content/drive/My Drive/Colab Notebooks/Stable diffusion/DAAM'\n",
        "os.chdir(folder_path)\n",
        "print(\"Current working directory: \", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boMP-pOdViUB",
        "outputId": "1b2e2ad8-f395-4518-908d-215406f96462"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory:  /content/drive/My Drive/Colab Notebooks/Stable diffusion/DAAM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "3UO5P0b_WCWP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.amp.autocast().__enter__()\n",
        "torch.set_grad_enabled(False);"
      ],
      "metadata": {
        "id": "rtSmmG-HXQD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxuCNoFZ5EWr"
      },
      "outputs": [],
      "source": [
        "import daam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHoHbZWe76EE"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from daam import set_seed, trace\n",
        "pipe = StableDiffusionPipeline.from_pretrained('stabilityai/stable-diffusion-2-1-base')\n",
        "pipe.to('cuda:0');"
      ],
      "metadata": {
        "id": "oyU_NeS7XhSB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('final_coco_dataframe.csv')"
      ],
      "metadata": {
        "id": "ti0y41kHWW5F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate DAAM Maps"
      ],
      "metadata": {
        "id": "UXjc2wjAXxxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "9_gcoqOQHSbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "def generate_images(df, start_idx=0, batch_size=2):\n",
        "    total_batches = (len(df) - start_idx) // batch_size + ((len(df) - start_idx) % batch_size > 0)\n",
        "    output_folder = Path('experiments')\n",
        "    output_folder.mkdir(exist_ok=True)\n",
        "\n",
        "    for batch_num in range(total_batches):\n",
        "        start = start_idx + batch_num * batch_size\n",
        "        end = min(start + batch_size, len(df))\n",
        "        batch_df = df.iloc[start:end]\n",
        "\n",
        "        for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f'Batch {batch_num+1}/{total_batches}'):\n",
        "            id, caption = row['id'], row['caption']\n",
        "            try:\n",
        "                gen = set_seed(id)\n",
        "                with torch.no_grad():\n",
        "                    with trace(pipe) as tc:\n",
        "                        out = pipe(caption, num_inference_steps=20, generator=gen)\n",
        "                        exp = tc.to_experiment(output_folder, id=str(id), seed=id)\n",
        "                        exp.save(output_folder, heat_maps=False)\n",
        "                torch.cuda.empty_cache()\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing id {id}: {e}\")\n",
        "\n",
        "        # Save progress after each batch\n",
        "        with open('progress.txt', 'w') as f:\n",
        "            f.write(str(end))\n",
        "\n",
        "# Check for existing progress and resume\n",
        "try:\n",
        "    with open('progress.txt', 'r') as f:\n",
        "        start_index = int(f.read().strip())\n",
        "except FileNotFoundError:\n",
        "    start_index = 0\n",
        "\n",
        "generate_images(df, start_idx=start_index)"
      ],
      "metadata": {
        "id": "z2EcdLpkHZXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the 'experiments' directory\n",
        "experiment_path = Path('experiments')\n",
        "\n",
        "# Use a generator expression to count directories\n",
        "folder_count = sum(1 for entry in experiment_path.iterdir() if entry.is_dir())\n",
        "\n",
        "print(f\"There are {folder_count} folders in {experiment_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0GHC138dO4a",
        "outputId": "37cf1e16-c7ef-49a4-c2b7-e39b49516200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 870 folders in experiments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse and analyse"
      ],
      "metadata": {
        "id": "KlSguNgSYJEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from daam import GenerationExperiment"
      ],
      "metadata": {
        "id": "LG1NJysSYMQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(a, b, t: float = 0.1) -> float:\n",
        "    intersection = (a > t) & (b > t)\n",
        "    union = (a > t) | (b > t)\n",
        "\n",
        "    i = intersection.float().sum()\n",
        "    u = union.float().sum()\n",
        "\n",
        "    if u < 1e-6:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return (i / u).item()"
      ],
      "metadata": {
        "id": "cHHFQyyRbpV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from daam import GenerationExperiment\n",
        "\n",
        "print(\"DataFrame loaded with {} rows.\".format(len(df)))\n",
        "\n",
        "stats = []\n",
        "\n",
        "# Use itertuples for more efficient row iteration\n",
        "for row in tqdm(df.itertuples(index=True), total=len(df)):\n",
        "    experiment_path = Path('experiments') / str(row.id)\n",
        "    if experiment_path.exists():\n",
        "        print(f\"Loading experiment from: {experiment_path}\")\n",
        "        exp = GenerationExperiment.load(experiment_path)\n",
        "    else:\n",
        "        print(f\"Experiment path does not exist: {experiment_path}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        heat_map = exp.heat_map()\n",
        "        word_maps = {}\n",
        "        words_of_interest = ['preposition', 'subject', 'object', 'verb']\n",
        "\n",
        "        for word_type in words_of_interest:\n",
        "            word = getattr(row, word_type)\n",
        "            if pd.notna(word):\n",
        "                try:\n",
        "                    word_maps[word_type] = heat_map.compute_word_heat_map(word).value.cuda()\n",
        "                except ValueError as ve:\n",
        "                    print(f\"Could not compute heat map for {word_type}: {word}, Error: {ve}\")\n",
        "\n",
        "        pairs_of_interest = [('preposition', 'subject'), ('preposition', 'object'), ('preposition', 'verb')]\n",
        "        for head_type, dep_type in pairs_of_interest:\n",
        "            if head_type in word_maps and dep_type in word_maps:\n",
        "                iou_value = iou(word_maps[head_type], word_maps[dep_type])\n",
        "                stats.append({\n",
        "                    'pair': f\"{head_type}-{dep_type}\",\n",
        "                    'preposition': getattr(row, 'preposition'),\n",
        "                    'iou': iou_value,\n",
        "                    'experiment_path': str(experiment_path)\n",
        "                })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {str(experiment_path)}: {str(e)}\")\n",
        "\n",
        "    # Clear memory after each row is processed\n",
        "    del exp\n",
        "    gc.collect()\n",
        "\n",
        "stats_df = pd.DataFrame(stats)\n",
        "print(\"Statistics collected:\")\n",
        "print(stats_df)"
      ],
      "metadata": {
        "id": "ZkdPKNy4buRJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_df['preposition'] = stats_df['preposition'].str.lower()"
      ],
      "metadata": {
        "id": "OHS96mJt_xp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_df.to_csv('stats_output.csv', index=False)"
      ],
      "metadata": {
        "id": "Ol6-vRsa5GVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aggregate statistics"
      ],
      "metadata": {
        "id": "zHHPobmy16wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of prepositions in the original DataFrame\n",
        "\n",
        "df['preposition'] = df['preposition'].str.lower()\n",
        "preposition_counts = df['preposition'].value_counts()\n",
        "\n",
        "preposition_counts_df = preposition_counts.reset_index()\n",
        "preposition_counts_df.columns = ['preposition', 'count']\n",
        "\n",
        "print(preposition_counts_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RINkclI66ZMo",
        "outputId": "090c0ccb-6e53-431a-8489-324f789018b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   preposition  count\n",
            "0           on    176\n",
            "1           in    147\n",
            "2         with    131\n",
            "3           of    112\n",
            "4      next to     39\n",
            "..         ...    ...\n",
            "56       in to      1\n",
            "57         out      1\n",
            "58          as      1\n",
            "59     towards      1\n",
            "60      across      1\n",
            "\n",
            "[61 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_std = preposition_counts_df['count'].std()\n",
        "print(f\"Overall standard deviation: {overall_std:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuMFs9tvebZ7",
        "outputId": "d85beed6-4ad7-4f6d-de70-071339e21400"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall standard deviation: 35.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the statistics DataFrame\n",
        "stats_df = pd.read_csv('stats_output.csv')"
      ],
      "metadata": {
        "id": "FI5dWZZJNUy9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean IoU across all pairs, ignoring prepositions\n",
        "mean_iou_all = stats_df['iou'].mean()\n",
        "rounded_mean_iou_percentage = round(mean_iou_all * 100, 4)\n",
        "print(\"Mean IoU across all pairs:\", rounded_mean_iou_percentage, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6rHmYh9-ncT",
        "outputId": "e33809cd-6f0a-4e8b-834f-3ea3d4d5a285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean IoU across all pairs: 6.088 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean IoU for each type of pair, ignoring prepositions\n",
        "mean_iou_by_pair = stats_df.groupby('pair').agg(mean_iou=('iou', 'mean'))\n",
        "\n",
        "# Convert to percentage\n",
        "mean_iou_by_pair['mean_iou'] = (mean_iou_by_pair['mean_iou'] * 100).round(4)\n",
        "\n",
        "# Sort from largest to smallest\n",
        "mean_iou_by_pair = mean_iou_by_pair.sort_values('mean_iou', ascending=False)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(\"Mean IoU by Pair (in %):\")\n",
        "print(mean_iou_by_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn_9Cs6f-qga",
        "outputId": "31b2bc77-6c8d-4ae8-a405-8a046d2d46fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean IoU by Pair (in %):\n",
            "                     mean_iou\n",
            "pair                         \n",
            "preposition-subject    9.5919\n",
            "preposition-verb       4.3271\n",
            "preposition-object     3.9066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust display settings to show full DataFrame without truncation\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Calculate the mean IoU and count for each preposition\n",
        "mean_iou_by_preposition = stats_df.groupby('preposition').agg(\n",
        "    mean_iou=('iou', 'mean'),\n",
        "    count=('iou', 'count')\n",
        ")\n",
        "\n",
        "# Convert mean IoU to percentage\n",
        "mean_iou_by_preposition['mean_iou'] = (mean_iou_by_preposition['mean_iou'] * 100).round(4)\n",
        "\n",
        "# Merge with preposition_counts_df to include the count\n",
        "mean_iou_by_preposition = mean_iou_by_preposition.merge(preposition_counts_df, on='preposition', how='left')\n",
        "\n",
        "# Sort from largest to smallest by mean IoU\n",
        "mean_iou_by_preposition = mean_iou_by_preposition.sort_values('mean_iou', ascending=False)\n",
        "\n",
        "# Display the first 30 entries\n",
        "mean_iou_by_preposition = mean_iou_by_preposition.head(30)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(\"Mean IoU by Preposition (in %), including counts:\")\n",
        "print(mean_iou_by_preposition)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F0bOZb_BPXU",
        "outputId": "6aeda46f-8a6e-4d27-ae39-5b45cbc9e708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean IoU by Preposition (in %), including counts:\n",
            "   preposition  mean_iou  count_x  count_y\n",
            "14     between   27.8215        3        1\n",
            "1        above   25.1762        6        2\n",
            "21      during   24.2776        3        1\n",
            "45        over   19.2372       36       12\n",
            "49     towards   17.8363        3        1\n",
            "50       under   15.2187       17        6\n",
            "59        with   14.4681      334      131\n",
            "2       across   13.6069        3        1\n",
            "11      behind   12.1306       22        8\n",
            "47     through   11.5124       21        7\n",
            "43     outside   11.3289       14        6\n",
            "57     wearing   10.9702       12        5\n",
            "5        among   10.2255        5        2\n",
            "40        onto    9.4358        9        3\n",
            "6       around    9.1239        9        3\n",
            "32        into    8.2703       15        5\n",
            "19        down    8.0870       75       25\n",
            "16          by    6.7752       46       16\n",
            "41         out    6.7213        3        1\n",
            "23        from    6.3497       26        9\n",
            "26          in    5.9013      409      147\n",
            "8           at    4.5406      113       38\n",
            "12      beside    4.2137        9        3\n",
            "58       while    4.1735       12        5\n",
            "36          of    4.1144      290      112\n",
            "25     holding    3.5702        4        2\n",
            "56       up to    3.4914        9        3\n",
            "38          on    3.3460      496      176\n",
            "3      against    2.4557        8        3\n",
            "30      inside    2.4206        6        2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust display settings to show full DataFrame without truncation\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Calculate the mean IoU and count for each type of pair and each preposition\n",
        "mean_iou_by_pair_and_preposition = stats_df.groupby(['pair', 'preposition']).agg(\n",
        "    mean_iou=('iou', 'mean'),\n",
        "    preposition_count=('iou', 'count')\n",
        ")\n",
        "\n",
        "# Convert mean IoU to percentage\n",
        "mean_iou_by_pair_and_preposition['mean_iou'] = (mean_iou_by_pair_and_preposition['mean_iou'] * 100).round(4)\n",
        "\n",
        "# Reset index to merge\n",
        "mean_iou_by_pair_and_preposition = mean_iou_by_pair_and_preposition.reset_index()\n",
        "\n",
        "# Merge with preposition_counts_df to include the count\n",
        "mean_iou_by_pair_and_preposition = mean_iou_by_pair_and_preposition.merge(preposition_counts_df[['preposition', 'count']], on='preposition', how='left')\n",
        "\n",
        "# Drop the original preposition_count column\n",
        "mean_iou_by_pair_and_preposition = mean_iou_by_pair_and_preposition.drop(columns=['preposition_count'])\n",
        "\n",
        "# Sort within each 'pair' group from largest to smallest by mean IoU\n",
        "mean_iou_by_pair_and_preposition = mean_iou_by_pair_and_preposition.sort_values(['pair', 'mean_iou'], ascending=[True, False])\n",
        "\n",
        "# Use groupby on 'pair' and apply a lambda to take the top 10 prepositions for each pair\n",
        "# Reset the index to keep the 'pair' and 'preposition' columns\n",
        "top_10_per_pair = mean_iou_by_pair_and_preposition.groupby('pair', group_keys=False).apply(lambda x: x.head(10)).reset_index(drop=True)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(\"Mean IoU by Pair and Preposition (in %), including preposition counts:\")\n",
        "print(top_10_per_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOouWGVeB-wA",
        "outputId": "d012871e-1710-497d-c129-159b2401265d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean IoU by Pair and Preposition (in %), including preposition counts:\n",
            "                   pair preposition  mean_iou  count\n",
            "0    preposition-object      during   30.8208      1\n",
            "1    preposition-object     wearing   15.1107      5\n",
            "2    preposition-object        onto   14.5926      3\n",
            "3    preposition-object     outside   13.3888      6\n",
            "4    preposition-object        with   11.4602    131\n",
            "5    preposition-object      beside   10.9091      3\n",
            "6    preposition-object       under   10.8165      6\n",
            "7    preposition-object        over   10.2918     12\n",
            "8    preposition-object          by    8.5471     16\n",
            "9    preposition-object       above    8.3502      2\n",
            "10  preposition-subject     between   83.4646      1\n",
            "11  preposition-subject      across   36.4754      1\n",
            "12  preposition-subject       above   34.7092      2\n",
            "13  preposition-subject      behind   27.3161      8\n",
            "14  preposition-subject        over   26.7186     12\n",
            "15  preposition-subject       among   25.5637      2\n",
            "16  preposition-subject      around   24.5671      3\n",
            "17  preposition-subject        with   22.7065    131\n",
            "18  preposition-subject         out   18.6047      1\n",
            "19  preposition-subject        into   16.6073      5\n",
            "20     preposition-verb     towards   44.8454      1\n",
            "21     preposition-verb      during   39.5664      1\n",
            "22     preposition-verb       above   32.4691      2\n",
            "23     preposition-verb       under   21.9644      6\n",
            "24     preposition-verb        over   20.7011     12\n",
            "25     preposition-verb     through   17.2450      7\n",
            "26     preposition-verb     outside   15.4453      6\n",
            "27     preposition-verb        down   13.0589     25\n",
            "28     preposition-verb        into    6.7608      5\n",
            "29     preposition-verb          in    6.0654    147\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "xqnhnUc3e2LP"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}