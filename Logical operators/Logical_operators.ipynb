{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "Eq-UwzDaTbHa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-GtexsATJUw",
        "outputId": "41741999-ab6f-4db4-c0dc-755336f9fbad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Go to the DAAM folder in Google Drive\n",
        "folder_path = '/content/drive/My Drive/Colab Notebooks/Stable diffusion/Logical operators'\n",
        "os.chdir(folder_path)\n",
        "print(\"Current working directory: \", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmOQzOtqTg-5",
        "outputId": "d83d37ef-402a-4d3a-8c10-da57fb63aa11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory:  /content/drive/My Drive/Colab Notebooks/Stable diffusion/Logical operators\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "_sa9OoXaTuEO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "vx_uvhZmgOUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load the Hugging Face token from a JSON file\n",
        "def load_hf_token(json_path):\n",
        "    with open(json_path, 'r') as json_file:\n",
        "        data = json.load(json_file)\n",
        "        return data['hf_token']\n",
        "\n",
        "hf_token = load_hf_token('config.json')"
      ],
      "metadata": {
        "id": "U9rb_dDdK8Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    'stabilityai/stable-diffusion-2-1-base',\n",
        "    revision=\"main\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=hf_token\n",
        ").to('cuda')"
      ],
      "metadata": {
        "id": "CeL268JNTo5_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#And"
      ],
      "metadata": {
        "id": "4DaJpErtTMZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load the dataframe"
      ],
      "metadata": {
        "id": "5r4A_81ljw4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('and')\n",
        "\n",
        "# Verify the current working directory\n",
        "print(\"Current working directory: \", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ6HFxotHD0g",
        "outputId": "5b4a033a-9a7e-4a3a-bda2-54b8aa8755a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory:  /content/drive/MyDrive/Colab Notebooks/Stable diffusion/Logical operators/and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('and_generated_sentences.csv')"
      ],
      "metadata": {
        "id": "jmx4nw8fUIXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new index column that uniquely identifies each row\n",
        "df['id'] = range(1, len(df) + 1)\n",
        "\n",
        "# Set the new index column as the first column\n",
        "cols = df.columns.tolist()  # Get a list of all columns\n",
        "cols = cols[-1:] + cols[:-1]  # Move the last column (new index) to the first position\n",
        "df = df[cols]  # Reassign sorted column DataFrame to df\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UolnrP-wUyVB",
        "outputId": "3067c788-e123-428d-fbd8-3f89ee3543b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sentence conjunction  \\\n",
            "0   1  A little girl and her dog are playing in the p...         and   \n",
            "1   2  An astronaut and a satellite are floating in s...         and   \n",
            "2   3  A ship and a lighthouse stand against the back...         and   \n",
            "3   4  A butterfly and a flower are in a vibrant meadow.         and   \n",
            "4   5  A knight and a dragon are locked in a fierce b...         and   \n",
            "\n",
            "    first_noun second_noun  \n",
            "0  Little girl     Her dog  \n",
            "1    Astronaut   Satellite  \n",
            "2         Ship  Lighthouse  \n",
            "3    Butterfly      Flower  \n",
            "4       Knight      Dragon  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate images"
      ],
      "metadata": {
        "id": "J1ckzDVXj0r6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "def generate_images(df, start_idx=0, batch_size=2):\n",
        "    print(\"Starting the image generation process.\")\n",
        "    total_batches = (len(df) - start_idx) // batch_size + ((len(df) - start_idx) % batch_size > 0)\n",
        "    output_folder = Path('images')\n",
        "    output_folder.mkdir(exist_ok=True)\n",
        "\n",
        "    print(f\"Total number of batches to process: {total_batches}\")\n",
        "    for batch_num in range(total_batches):\n",
        "        start = start_idx + batch_num * batch_size\n",
        "        end = min(start + batch_size, len(df))\n",
        "        batch_df = df.iloc[start:end]\n",
        "        print(f\"Processing batch {batch_num + 1}/{total_batches} - from index {start} to {end}\")\n",
        "\n",
        "        for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f'Batch {batch_num+1}/{total_batches}'):\n",
        "            id, sentence = row['id'], row['sentence']\n",
        "            print(f\"Generating image for ID {id} with prompt: {sentence}\")\n",
        "            try:\n",
        "                gen = torch.Generator().manual_seed(id)\n",
        "                with torch.no_grad():\n",
        "                    # Generate the image\n",
        "                    out = pipe(sentence, num_inference_steps=50, generator=gen)\n",
        "                # Save the image\n",
        "                img = out.images[0]\n",
        "                img_path = output_folder / f'{id}.png'\n",
        "                img.save(img_path)\n",
        "                print(f\"Image saved to {img_path}\")\n",
        "                torch.cuda.empty_cache()\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing ID {id}: {e}\")\n",
        "\n",
        "        # Save progress after each batch\n",
        "        with open('progress.txt', 'w') as f:\n",
        "            f.write(str(end))\n",
        "        print(f\"Progress saved, batch {batch_num + 1} complete.\")\n",
        "\n",
        "# Check for existing progress and resume\n",
        "try:\n",
        "    with open('progress.txt', 'r') as f:\n",
        "        start_index = int(f.read().strip())\n",
        "        print(f\"Resuming from index {start_index}\")\n",
        "except FileNotFoundError:\n",
        "    start_index = 0\n",
        "    print(\"Starting from the beginning\")\n",
        "\n",
        "generate_images(df, start_idx=start_index)"
      ],
      "metadata": {
        "id": "89r9grPqcfN1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Answer questions about images"
      ],
      "metadata": {
        "id": "hS2_YsODj4gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_cNWhORj8Gn",
        "outputId": "c4a6d672-0695-4b33-a870-867987ab954a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from transformers import pipeline\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the visual question-answering model\n",
        "vqa_pipeline = pipeline(\"visual-question-answering\", model=\"dandelin/vilt-b32-finetuned-vqa\", use_auth_token=hf_token)\n",
        "\n",
        "def detect_object_in_image(image_path, object_name):\n",
        "    image = Image.open(image_path)\n",
        "    question = f\"Is there a {object_name} in this picture?\"\n",
        "\n",
        "    try:\n",
        "        response = vqa_pipeline(image, question, top_k=1)\n",
        "        print(\"Pipeline response:\", response)\n",
        "\n",
        "        answer = response[0]['answer'].lower() if isinstance(response, list) else response['answer'].lower()\n",
        "\n",
        "        if 'yes' in answer or 'there is' in answer:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "mXSCUgdSkE0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_df_with_image_analysis(df):\n",
        "    df['first_noun_presence'] = False\n",
        "    df['second_noun_presence'] = False\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        image_path = Path('images') / f\"{row['id']}.png\"\n",
        "        if image_path.exists():\n",
        "            df.at[index, 'first_noun_presence'] = detect_object_in_image(image_path, row['first_noun'])\n",
        "            df.at[index, 'second_noun_presence'] = detect_object_in_image(image_path, row['second_noun'])\n",
        "        else:\n",
        "            print(f\"No image found for ID {row['id']}\")\n",
        "\n",
        "update_df_with_image_analysis(df)"
      ],
      "metadata": {
        "id": "Y8-f-AiPkLci",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4cCQVzzlvRq",
        "outputId": "8a5e30d0-6b7c-4c7d-a215-392121149229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sentence conjunction  \\\n",
            "0   1  A little girl and her dog are playing in the p...         and   \n",
            "1   2  An astronaut and a satellite are floating in s...         and   \n",
            "2   3  A ship and a lighthouse stand against the back...         and   \n",
            "3   4  A butterfly and a flower are in a vibrant meadow.         and   \n",
            "4   5  A knight and a dragon are locked in a fierce b...         and   \n",
            "\n",
            "    first_noun second_noun  first_noun_presence  second_noun_presence  \n",
            "0  Little girl     Her dog                 True                  True  \n",
            "1    Astronaut   Satellite                 True                  True  \n",
            "2         Ship  Lighthouse                 True                  True  \n",
            "3    Butterfly      Flower                 True                  True  \n",
            "4       Knight      Dragon                 True                  True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['answer_check'] = df.apply(lambda x: x['first_noun_presence'] and x['second_noun_presence'], axis=1)"
      ],
      "metadata": {
        "id": "DUGoIQh_kNia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVmitZgnMf_h",
        "outputId": "92ba8b8b-4b11-4d43-de39-13b189ad40a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sentence conjunction  \\\n",
            "0   1  A little girl and her dog are playing in the p...         and   \n",
            "1   2  An astronaut and a satellite are floating in s...         and   \n",
            "2   3  A ship and a lighthouse stand against the back...         and   \n",
            "3   4  A butterfly and a flower are in a vibrant meadow.         and   \n",
            "4   5  A knight and a dragon are locked in a fierce b...         and   \n",
            "\n",
            "    first_noun second_noun  first_noun_presence  second_noun_presence  \\\n",
            "0  Little girl     Her dog                 True                  True   \n",
            "1    Astronaut   Satellite                 True                  True   \n",
            "2         Ship  Lighthouse                 True                  True   \n",
            "3    Butterfly      Flower                 True                  True   \n",
            "4       Knight      Dragon                 True                  True   \n",
            "\n",
            "   answer_check  \n",
            "0          True  \n",
            "1          True  \n",
            "2          True  \n",
            "3          True  \n",
            "4          True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"and_updated_dataframe.csv\", index=False)"
      ],
      "metadata": {
        "id": "Gz255XMYkRFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of True values in the 'answer_check' column\n",
        "percentage_true = (df['answer_check'].sum() / len(df['answer_check'])) * 100\n",
        "\n",
        "# Output the percentage\n",
        "print(f\"The percentage of True values is: {percentage_true:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8ZPowBQMw9r",
        "outputId": "6bab659e-c419-4f7c-bdf4-b2491977bded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage of True values is: 68.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Or"
      ],
      "metadata": {
        "id": "ycB13ObITRSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load the dataframe"
      ],
      "metadata": {
        "id": "BCCHiuiRPCDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/Colab Notebooks/Stable diffusion/Logical operators'\n",
        "os.chdir(folder_path)"
      ],
      "metadata": {
        "id": "Py1dSQstPPFe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('or')\n",
        "\n",
        "# Verify the current working directory\n",
        "print(\"Current working directory: \", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0208a784-e284-4e78-e0ca-4a782bde0e0b",
        "id": "RyQZDVtbPCDG"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory:  /content/drive/My Drive/Colab Notebooks/Stable diffusion/Logical operators/or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('or_generated_sentences.csv')"
      ],
      "metadata": {
        "id": "PB9IeZHnPCDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new index column that uniquely identifies each row\n",
        "df['id'] = range(1, len(df) + 1)\n",
        "\n",
        "# Set the new index column as the first column\n",
        "cols = df.columns.tolist()  # Get a list of all columns\n",
        "cols = cols[-1:] + cols[:-1]  # Move the last column (new index) to the first position\n",
        "df = df[cols]  # Reassign sorted column DataFrame to df\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625648f8-6d5a-436f-d4d5-180e334f4ff6",
        "id": "UG1P0Mt_PCDH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sentence conjunction  \\\n",
            "0   1    A girl is holding a red balloon or a blue kite.          or   \n",
            "1   2  An old man is feeding pigeons or reading a new...          or   \n",
            "2   3  A child is building a sandcastle or collecting...          or   \n",
            "3   4  A woman is watering her plants or hanging laun...          or   \n",
            "4   5  A cat is playing with a ball of yarn or sleepi...          or   \n",
            "\n",
            "                    first_noun                second_noun  \n",
            "0                  Red balloon                  Blue kite  \n",
            "1              Feeding pigeons        Reading a newspaper  \n",
            "2        Building a sandcastle       Collecting seashells  \n",
            "3              Watering plants            Hanging laundry  \n",
            "4  Playing with a ball of yarn  Sleeping on a comfy chair  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate images"
      ],
      "metadata": {
        "id": "qcNEr7vUPF4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "def generate_images(df, start_idx=0, batch_size=2):\n",
        "    print(\"Starting the image generation process.\")\n",
        "    total_batches = (len(df) - start_idx) // batch_size + ((len(df) - start_idx) % batch_size > 0)\n",
        "    output_folder = Path('images')\n",
        "    output_folder.mkdir(exist_ok=True)\n",
        "\n",
        "    print(f\"Total number of batches to process: {total_batches}\")\n",
        "    for batch_num in range(total_batches):\n",
        "        start = start_idx + batch_num * batch_size\n",
        "        end = min(start + batch_size, len(df))\n",
        "        batch_df = df.iloc[start:end]\n",
        "        print(f\"Processing batch {batch_num + 1}/{total_batches} - from index {start} to {end}\")\n",
        "\n",
        "        for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f'Batch {batch_num+1}/{total_batches}'):\n",
        "            id, sentence = row['id'], row['sentence']\n",
        "            print(f\"Generating image for ID {id} with prompt: {sentence}\")\n",
        "            try:\n",
        "                gen = torch.Generator().manual_seed(id)\n",
        "                with torch.no_grad():\n",
        "                    # Generate the image\n",
        "                    out = pipe(sentence, num_inference_steps=50, generator=gen)\n",
        "                # Save the image\n",
        "                img = out.images[0]\n",
        "                img_path = output_folder / f'{id}.png'\n",
        "                img.save(img_path)\n",
        "                print(f\"Image saved to {img_path}\")\n",
        "                torch.cuda.empty_cache()\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing ID {id}: {e}\")\n",
        "\n",
        "        # Save progress after each batch\n",
        "        with open('progress.txt', 'w') as f:\n",
        "            f.write(str(end))\n",
        "        print(f\"Progress saved, batch {batch_num + 1} complete.\")\n",
        "\n",
        "# Check for existing progress and resume\n",
        "try:\n",
        "    with open('progress.txt', 'r') as f:\n",
        "        start_index = int(f.read().strip())\n",
        "        print(f\"Resuming from index {start_index}\")\n",
        "except FileNotFoundError:\n",
        "    start_index = 0\n",
        "    print(\"Starting from the beginning\")\n",
        "\n",
        "generate_images(df, start_idx=start_index)"
      ],
      "metadata": {
        "id": "w2iLeWRlPF4v",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Answer questions about images"
      ],
      "metadata": {
        "id": "gLdMkvKnO5vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e2ec36-8854-4fea-d957-d970e0248e39",
        "id": "Z01jpXGqO5vv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from transformers import pipeline\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the visual question-answering model\n",
        "vqa_pipeline = pipeline(\"visual-question-answering\", model=\"dandelin/vilt-b32-finetuned-vqa\", use_auth_token=hf_token)\n",
        "\n",
        "def detect_object_in_image(image_path, object_name):\n",
        "    image = Image.open(image_path)\n",
        "    question = f\"Is there a {object_name} in this picture?\"\n",
        "\n",
        "    try:\n",
        "        response = vqa_pipeline(image, question, top_k=1)\n",
        "        print(\"Pipeline response:\", response)\n",
        "\n",
        "        answer = response[0]['answer'].lower() if isinstance(response, list) else response['answer'].lower()\n",
        "\n",
        "        if 'yes' in answer or 'there is' in answer:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "DF5WuIijO5vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_df_with_image_analysis(df):\n",
        "    df['first_noun_presence'] = False\n",
        "    df['second_noun_presence'] = False\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        image_path = Path('images') / f\"{row['id']}.png\"\n",
        "        if image_path.exists():\n",
        "            df.at[index, 'first_noun_presence'] = detect_object_in_image(image_path, row['first_noun'])\n",
        "            df.at[index, 'second_noun_presence'] = detect_object_in_image(image_path, row['second_noun'])\n",
        "        else:\n",
        "            print(f\"No image found for ID {row['id']}\")\n",
        "\n",
        "update_df_with_image_analysis(df)"
      ],
      "metadata": {
        "id": "I6BsvtU-O5vv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b795c1c-5d2a-438a-e7b3-bbdd9b29ba40",
        "id": "1pmL6EeTO5vw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sentence conjunction  \\\n",
            "0   1    A girl is holding a red balloon or a blue kite.          or   \n",
            "1   2  An old man is feeding pigeons or reading a new...          or   \n",
            "2   3  A child is building a sandcastle or collecting...          or   \n",
            "3   4  A woman is watering her plants or hanging laun...          or   \n",
            "4   5  A cat is playing with a ball of yarn or sleepi...          or   \n",
            "\n",
            "                    first_noun                second_noun  \\\n",
            "0                  Red balloon                  Blue kite   \n",
            "1              Feeding pigeons        Reading a newspaper   \n",
            "2        Building a sandcastle       Collecting seashells   \n",
            "3              Watering plants            Hanging laundry   \n",
            "4  Playing with a ball of yarn  Sleeping on a comfy chair   \n",
            "\n",
            "   first_noun_presence  second_noun_presence  answer_check  \n",
            "0                 True                  True         False  \n",
            "1                 True                  True         False  \n",
            "2                 True                 False          True  \n",
            "3                 True                  True         False  \n",
            "4                 True                  True         False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['answer_check'] = df.apply(lambda x: x['first_noun_presence'] ^ x['second_noun_presence'], axis=1)"
      ],
      "metadata": {
        "id": "VBge0KNsO5vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f1f351-bd2c-4ae2-9771-94ed60d61cdb",
        "id": "Q7rmnrRlO5vw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sentence conjunction  \\\n",
            "0   1    A girl is holding a red balloon or a blue kite.          or   \n",
            "1   2  An old man is feeding pigeons or reading a new...          or   \n",
            "2   3  A child is building a sandcastle or collecting...          or   \n",
            "3   4  A woman is watering her plants or hanging laun...          or   \n",
            "4   5  A cat is playing with a ball of yarn or sleepi...          or   \n",
            "\n",
            "                    first_noun                second_noun  \\\n",
            "0                  Red balloon                  Blue kite   \n",
            "1              Feeding pigeons        Reading a newspaper   \n",
            "2        Building a sandcastle       Collecting seashells   \n",
            "3              Watering plants            Hanging laundry   \n",
            "4  Playing with a ball of yarn  Sleeping on a comfy chair   \n",
            "\n",
            "   first_noun_presence  second_noun_presence  answer_check  \n",
            "0                 True                  True         False  \n",
            "1                 True                  True         False  \n",
            "2                 True                 False          True  \n",
            "3                 True                  True         False  \n",
            "4                 True                  True         False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"or_updated_dataframe.csv\", index=False)"
      ],
      "metadata": {
        "id": "QZXP844oO5vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of True values in the 'answer_check' column\n",
        "percentage_true = (df['answer_check'].sum() / len(df['answer_check'])) * 100\n",
        "\n",
        "# Output the percentage\n",
        "print(f\"The percentage of True values is: {percentage_true:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9887264a-d191-4e32-d7ed-d93dce122aaf",
        "id": "eCvXS4-PO5vw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage of True values is: 36.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Negation"
      ],
      "metadata": {
        "id": "zzqSe8kqTOZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load the dataframe"
      ],
      "metadata": {
        "id": "wWOTU3PXT9ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/Colab Notebooks/Stable diffusion/Logical operators'\n",
        "os.chdir(folder_path)"
      ],
      "metadata": {
        "id": "TzaeugxMT9ee"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('negation')\n",
        "\n",
        "# Verify the current working directory\n",
        "print(\"Current working directory: \", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94772533-3a58-489b-958d-379d4ae28506",
        "id": "zTbPa0tWT9ee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory:  /content/drive/My Drive/Colab Notebooks/Stable diffusion/Logical operators/negation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('negation_generated_sentences.csv')"
      ],
      "metadata": {
        "id": "x_PVUYw1T9ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new index column that uniquely identifies each row\n",
        "df['id'] = range(1, len(df) + 1)\n",
        "\n",
        "# Set the new index column as the first column\n",
        "cols = df.columns.tolist()  # Get a list of all columns\n",
        "cols = cols[-1:] + cols[:-1]  # Move the last column (new index) to the first position\n",
        "df = df[cols]  # Reassign sorted column DataFrame to df\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ba0c57-2fb1-4486-e0ec-3c900e93d01e",
        "id": "wfctPJuTT9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sentence negation negated_noun\n",
            "0   1                 The tree does not have any leaves.      Not       Leaves\n",
            "1   2                 There is no moon in the night sky.       No         Moon\n",
            "2   3                The room is not filled with people.      Not       People\n",
            "3   4              There isn't a single bird in the sky.    Isn't         Bird\n",
            "4   5  The playground is empty, no children are playing.       No     Children\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate images"
      ],
      "metadata": {
        "id": "7XG__itIUAqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "def generate_images(df, start_idx=0, batch_size=2):\n",
        "    print(\"Starting the image generation process.\")\n",
        "    total_batches = (len(df) - start_idx) // batch_size + ((len(df) - start_idx) % batch_size > 0)\n",
        "    output_folder = Path('images')\n",
        "    output_folder.mkdir(exist_ok=True)\n",
        "\n",
        "    print(f\"Total number of batches to process: {total_batches}\")\n",
        "    for batch_num in range(total_batches):\n",
        "        start = start_idx + batch_num * batch_size\n",
        "        end = min(start + batch_size, len(df))\n",
        "        batch_df = df.iloc[start:end]\n",
        "        print(f\"Processing batch {batch_num + 1}/{total_batches} - from index {start} to {end}\")\n",
        "\n",
        "        for _, row in tqdm(batch_df.iterrows(), total=len(batch_df), desc=f'Batch {batch_num+1}/{total_batches}'):\n",
        "            id, sentence = row['id'], row['sentence']\n",
        "            print(f\"Generating image for ID {id} with prompt: {sentence}\")\n",
        "            try:\n",
        "                gen = torch.Generator().manual_seed(id)\n",
        "                with torch.no_grad():\n",
        "                    # Generate the image\n",
        "                    out = pipe(sentence, num_inference_steps=50, generator=gen)\n",
        "                # Save the image\n",
        "                img = out.images[0]\n",
        "                img_path = output_folder / f'{id}.png'\n",
        "                img.save(img_path)\n",
        "                print(f\"Image saved to {img_path}\")\n",
        "                torch.cuda.empty_cache()\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing ID {id}: {e}\")\n",
        "\n",
        "        # Save progress after each batch\n",
        "        with open('progress.txt', 'w') as f:\n",
        "            f.write(str(end))\n",
        "        print(f\"Progress saved, batch {batch_num + 1} complete.\")\n",
        "\n",
        "# Check for existing progress and resume\n",
        "try:\n",
        "    with open('progress.txt', 'r') as f:\n",
        "        start_index = int(f.read().strip())\n",
        "        print(f\"Resuming from index {start_index}\")\n",
        "except FileNotFoundError:\n",
        "    start_index = 0\n",
        "    print(\"Starting from the beginning\")\n",
        "\n",
        "generate_images(df, start_idx=start_index)"
      ],
      "metadata": {
        "id": "09N7D90RUAqN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Answer questions about images"
      ],
      "metadata": {
        "id": "hBYbUMR3UGv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1890f9bc-a929-43c3-88c7-ffe817f05ec1",
        "id": "6n2XOM0bUGv-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from transformers import pipeline\n",
        "from pathlib import Path\n",
        "\n",
        "# Load the visual question-answering model\n",
        "vqa_pipeline = pipeline(\"visual-question-answering\", model=\"dandelin/vilt-b32-finetuned-vqa\", use_auth_token=hf_token)\n",
        "\n",
        "def detect_object_in_image(image_path, object_name):\n",
        "    image = Image.open(image_path)\n",
        "    question = f\"Is there a {object_name} in this picture?\"\n",
        "\n",
        "    try:\n",
        "        response = vqa_pipeline(image, question, top_k=1)\n",
        "        print(\"Pipeline response:\", response)\n",
        "\n",
        "        answer = response[0]['answer'].lower() if isinstance(response, list) else response['answer'].lower()\n",
        "\n",
        "        if 'yes' in answer or 'there is' in answer:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "CkAydi2uUGv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_df_with_image_analysis(df):\n",
        "    df['negated_noun_presence'] = False\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        image_path = Path('images') / f\"{row['id']}.png\"\n",
        "        if image_path.exists():\n",
        "            df.at[index, 'negated_noun_presence'] = detect_object_in_image(image_path, row['negated_noun'])\n",
        "        else:\n",
        "            print(f\"No image found for ID {row['id']}\")\n",
        "\n",
        "update_df_with_image_analysis(df)"
      ],
      "metadata": {
        "id": "z8dO6BIoUGv_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18b104d-242e-4ec5-d565-353cff3e7f85",
        "id": "HLYpM3kUUGv_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sentence negation  \\\n",
            "0   1                 The tree does not have any leaves.      Not   \n",
            "1   2                 There is no moon in the night sky.       No   \n",
            "2   3                The room is not filled with people.      Not   \n",
            "3   4              There isn't a single bird in the sky.    Isn't   \n",
            "4   5  The playground is empty, no children are playing.       No   \n",
            "\n",
            "  negated_noun  negated_noun_presence  \n",
            "0       Leaves                  False  \n",
            "1         Moon                   True  \n",
            "2       People                  False  \n",
            "3         Bird                   True  \n",
            "4     Children                  False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['answer_check'] = df.apply(lambda x: not x['negated_noun_presence'], axis=1)"
      ],
      "metadata": {
        "id": "PQCE_u0RUGv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d99227-1334-46e3-912b-72c3e22e7a29",
        "id": "ulMtdEB9UGwA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                           sentence negation  \\\n",
            "0   1                 The tree does not have any leaves.      Not   \n",
            "1   2                 There is no moon in the night sky.       No   \n",
            "2   3                The room is not filled with people.      Not   \n",
            "3   4              There isn't a single bird in the sky.    Isn't   \n",
            "4   5  The playground is empty, no children are playing.       No   \n",
            "\n",
            "  negated_noun  negated_noun_presence  answer_check  \n",
            "0       Leaves                  False          True  \n",
            "1         Moon                   True         False  \n",
            "2       People                  False          True  \n",
            "3         Bird                   True         False  \n",
            "4     Children                  False          True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"negation_updated_dataframe.csv\", index=False)"
      ],
      "metadata": {
        "id": "mN7-lubOUGwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of True values in the 'answer_check' column\n",
        "percentage_true = (df['answer_check'].sum() / len(df['answer_check'])) * 100\n",
        "\n",
        "# Output the percentage\n",
        "print(f\"The percentage of True values is: {percentage_true:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f5db9b-0905-4c56-c9f5-bd9e6ffb58a1",
        "id": "kl7Z4csVUGwA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage of True values is: 40.00%\n"
          ]
        }
      ]
    }
  ]
}